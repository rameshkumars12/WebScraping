{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f899c618",
   "metadata": {},
   "source": [
    "### Step 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d666e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.naukri.com/data-science-jobs-in-chennai?k=data%20science&l=chennai\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403508c",
   "metadata": {},
   "source": [
    "### Step 2: Getting The Page Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f42b6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4ffda7ae85cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchromedriver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mnext_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"pagination mt-64 mb-60\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mpage_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"fright fs14 btn-secondary br2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mbase_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"https://www.naukri.com{page_link}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "#Setting the driver has a function\n",
    "Page_Links = []\n",
    "for index,links in enumerate(url):\n",
    "    if index == 10:\n",
    "        break\n",
    "    else:\n",
    "        def chromedriver(x):\n",
    "            driver = webdriver.Chrome(\"D:\\\\ChromeD\\\\chromedriver.exe\")\n",
    "            driver.get(x)\n",
    "            time.sleep(2)\n",
    "            soup = bs(driver.page_source,\"html5lib\")\n",
    "            driver.close()\n",
    "            return soup\n",
    "        page = chromedriver(url)\n",
    "        next_page = page.find(class_ = \"pagination mt-64 mb-60\")\n",
    "        page_link = next_page.find(class_ = \"fright fs14 btn-secondary br2\")[\"href\"]\n",
    "        base_path = f\"https://www.naukri.com{page_link}\"\n",
    "        url = base_path\n",
    "        Page_Links.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1213746",
   "metadata": {},
   "source": [
    "### Step 3: Scraping The Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDesc = []\n",
    "for urls in Page_Links:\n",
    "    page_soup = chromedriver(urls)\n",
    "    get_list = page_soup.find(class_ = \"list\")\n",
    "    \n",
    "    for index,post in enumerate(get_list.find_all(class_ = \"jobTuple bgWhite br4 mb-8\")):\n",
    "        #getting the title\n",
    "        try:\n",
    "            get_title = post.find(class_ = \"title fw500 ellipsis\").get_text()\n",
    "        except:\n",
    "            get_title = \" \"\n",
    "\n",
    "        #getting the company name\n",
    "        try:\n",
    "            get_company = post.find('a',class_='subTitle ellipsis fleft').get_text()\n",
    "        except:\n",
    "            get_company = \" \"\n",
    "\n",
    "        #getting company rating\n",
    "        try:\n",
    "            get_rating = post.find('span',class_='starRating fleft dot').get_text()\n",
    "        except:\n",
    "            get_rating = \" \"\n",
    "\n",
    "        #getting company review count\n",
    "        try:\n",
    "            get_review = post.find('a',class_='reviewsCount ml-5 fleft blue-text').get_text()\n",
    "        except:\n",
    "            get_review = \" \" \n",
    "\n",
    "        #getting the experience needed\n",
    "        try:\n",
    "            experience = post.find('li',class_='fleft grey-text br2 placeHolderLi experience')\n",
    "            get_experience = experience.find('span',class_='ellipsis fleft fs12 lh16').get_text()\n",
    "        except:\n",
    "            get_experience = \" \"\n",
    "\n",
    "        #getting the salary details \n",
    "        try:\n",
    "            get_salary = post.find(class_ = \"fleft grey-text br2 placeHolderLi salary\").get_text()\n",
    "        except:\n",
    "            get_salary = \" \"\n",
    "\n",
    "        #getting the location details\n",
    "        try:\n",
    "            get_location = post.find(class_ = \"fleft grey-text br2 placeHolderLi location\").get_text()\n",
    "        except:\n",
    "            get_location = \" \"\n",
    "\n",
    "        #getting skills required\n",
    "        try:\n",
    "            get_skills = post.find(class_ = \"tags has-description\" ).get_text(\",\", strip = True)\n",
    "        except:\n",
    "            get_skills = \" \"\n",
    "\n",
    "        #getting the post link\n",
    "        try:\n",
    "            get_link = post.find(class_ = \"title fw500 ellipsis\").get(\"href\")\n",
    "        except:\n",
    "            get_link = \" \"\n",
    "\n",
    "        #Storing the data in a dictionary\n",
    "        Other_details = {\"Company\": get_company,\n",
    "                \"Rating\" : get_rating,\n",
    "                \"Review Count\" : get_review, \n",
    "                \"Title\" : get_title,\n",
    "                \"Experience\" : get_experience,\n",
    "                \"Salary\" : get_salary,\n",
    "                \"Location\" : get_location,\n",
    "                \"Skills\" : get_skills,\n",
    "                \"Link\" : get_link,\n",
    "                }    \n",
    "\n",
    "\n",
    "        post_link = post.find(class_ = \"title fw500 ellipsis\")[\"href\"]\n",
    "        post_soup = chromedriver(post_link)\n",
    "\n",
    "        try:\n",
    "            content_list = post_soup.find(class_ = \"jdContainer job-desc\")\n",
    "            for job_desc in content_list.find(class_ = \"getJobDescriptionOtherDetails JD av_textblock_section jDisc mt25\"):\n",
    "                get_lab = job_desc.find(\"em\").get_text().replace(\":\", \"\")\n",
    "                get_span = job_desc.find(\"span\").get_text()\n",
    "                Other_details[get_lab] = get_span\n",
    "            JobDesc.append(Other_details)\n",
    "        except:\n",
    "            content_list = post_soup.find(class_ = \"job-desc\")\n",
    "            for job_desc in content_list.find_all(class_ = \"details\"):\n",
    "                get_lab = job_desc.find(\"label\").get_text().replace(\":\", \"\")\n",
    "                get_sp = job_desc.find(\"span\").get_text()\n",
    "                Other_details[get_lab] = get_sp\n",
    "            JobDesc.append(Other_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db7aeb3",
   "metadata": {},
   "source": [
    "### Step 4: Converting List to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6009ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(JobDesc)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e2471",
   "metadata": {},
   "source": [
    "### Step 5: Saving the DataFrame to Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3239c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Chennai Ds Job DataSet.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
